# 📅 2025-12-04 ~ 12-05 每日总结

## 🎯 主要任务

**AI数字人视频生成技术调研** - 为NDC Episode 1（1920年代侦探游戏）制作数字人口播视频，实现角色对话动画

---

## ✅ 完成的工作

### 1. ComfyUI 环境搭建

- 安装ComfyUI本地环境
- 配置RTX 4070 (12GB VRAM) GPU加速
- 安装多个自定义节点包

---

### 2. ComfyUI插件安装

| 插件名称 | 功能 |
|---------|------|
| ComfyUI-LivePortraitKJ | 表情迁移，从驱动视频提取动作 |
| ComfyUI-Impact-Pack | 人脸修复、图像增强 |
| ComfyUI-WanVideoWrapper | Wan视频生成、MultiTalk |
| ComfyUI-AudioScheduler | 音频处理 |
| audio-separation-nodes-comfyui | 音频分离 |
| ComfyUI-VideoHelperSuite | 视频加载/保存 |

---

### 3. 口型同步方案测试

#### 方案A: LivePortrait + 可灵Lip-Sync API ✅ 已成功测试
- **流程**: 图片 → LivePortrait生成动作视频 → FFmpeg缩放 → 可灵API对口型
- **优点**: 效果较好，支持高分辨率
- **缺点**: 需要付费API调用

#### 方案B: Wav2Lip ⚠️ 效果不理想
- **流程**: 视频 + 音频 → Wav2Lip节点 → 对口型视频
- **优点**: 本地免费运行
- **缺点**: 96x96低分辨率处理导致嘴部模糊

#### 方案C: MultiTalk (WanVideo) ❌ 模型太大未测试
- **流程**: 图片 + 音频 → 14B模型 → 说话视频
- **优点**: 端到端生成
- **缺点**: 需要下载~20GB模型，14B模型显存要求高

#### 方案D: HunyuanVideo-Avatar (腾讯) ❌ 暂不支持ComfyUI
- **功能**: 音频驱动人物动画，支持情感控制
- **显存**: 最低24GB，TeaCache优化版10GB

---

### 4. 已实现的工作流

**LivePortrait 图生视频**:
```
输入: 人物图片 + 驱动视频(表情动作)
输出: 人物按驱动视频做动作的视频
```

**可灵API对口型**:
```
输入: 视频(需≥512px高度) + 音频
输出: 口型同步的视频
处理: 若视频尺寸不足，用FFmpeg缩放
      ffmpeg -y -i input.mp4 -vf "scale=-2:512" output.mp4
```

---

### 5. API集成

| API | 功能 | 脚本位置 |
|-----|------|----------|
| 可灵 Kling AI | 文生图、图生视频、数字人口播、Lip-Sync | `scripts/kling_api.py` |
| LibLib AI | 文生图 | `scripts/liblib_api.py` |
| 阿里云OSS | 文件上传供API调用 | - |

---

## 🌟 关键成果与亮点

### 最佳方案确定
**描述**: LivePortrait(免费本地) + 可灵Lip-Sync API(付费)
**亮点**: 在质量和成本之间取得较好平衡，LivePortrait提供表情动作，可灵API处理精确口型同步

### 生成的测试文件

| 文件 | 说明 |
|-----|------|
| LivePortrait_00001.mp4 | LivePortrait生成，512x400 |
| LivePortrait_00002.mp4 | LivePortrait生成，1024x1024 |
| LivePortrait_00005.mp4 | LivePortrait生成，效果最佳 |
| liveportrait_lipsync.mp4 | 可灵API对口型输出 |
| liveportrait2_lipsync.mp4 | 可灵API对口型输出 |
| liveportrait5_lipsync.mp4 | 可灵API对口型输出 |

---

## 💡 关键收获与经验

### 问题与解决方案

| 问题 | 解决方案 |
|-----|---------|
| MaskPreview+节点缺失 | 删除红色节点或安装Impact-Pack |
| 可灵API视频高度<512px | FFmpeg缩放: `scale=-2:512` |
| ReActor仓库被GitHub禁用 | 改用Impact-Pack进行人脸修复 |
| AudioCrop节点缺失 | 安装audio-separation-nodes-comfyui |
| pip权限错误(cv2.pyd锁定) | 重启ComfyUI后再安装 |
| Windows编码错误(GBK) | 设置PYTHONIOENCODING=utf-8 |

---

## 📝 待完成事项

- [ ] 继续优化LivePortrait + 可灵Lip-Sync方案
- [ ] 等待HunyuanVideo-Avatar支持ComfyUI
- [ ] 制作完整的角色对话视频流程
- [ ] 探索更高质量的本地口型同步方案

---

## 🎯 下一步计划

1. **方案优化**: 继续优化LivePortrait + 可灵Lip-Sync工作流
2. **新技术跟进**: 关注HunyuanVideo-Avatar的ComfyUI支持进展
3. **完整流程**: 制作端到端的角色对话视频生成流程
4. **本地方案**: 探索更高质量的免费本地口型同步方案

---

## 📁 核心文件路径

**API脚本**: `d:\NDC_project\scripts\kling_api.py`

**ComfyUI工作流**: ComfyUI本地环境

**测试输出**: LivePortrait生成的视频文件

---

**文档生成时间**: 2025-12-05
**研究主题**: AI数字人视频生成
**关键工具**: ComfyUI, LivePortrait, 可灵API, FFmpeg
